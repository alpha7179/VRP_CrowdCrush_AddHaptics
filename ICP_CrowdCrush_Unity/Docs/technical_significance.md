# 기술적 구현의 의의 (Technical Significance)

본 프로젝트는 단순한 '체험'을 넘어 '생존 훈련'이라는 교육적 목표를 달성하기 위해, 수업 시간에 다룬 VR 핵심 이론을 코드 레벨에서 정교하게 구현하였습니다. 몰입감을 위한 **자유 이동(Continuous Locomotion)**과 이를 뒷받침하는 **안전 기술(Safety Tech)**, 그리고 편의성과 사실성을 고려하여 분리 설계된 **인터랙션(Interaction)**에 중점을 두었습니다.

### 1. Place Illusion: 고품질 환경 구현을 통한 장소 착각

사용자가 VR 공간을 단순한 그래픽이 아닌 '실제 장소'로 인식하기 위해서는 시각적, 청각적 충실도가 필수적입니다.

- **Realistic Environment**: 본 프로젝트는 실제 도시 환경을 모사한 고품질 3D 에셋(`Tokyo_Street`)을 기반으로, HDRP/URP 파이프라인의 사실적인 라이팅을 적용하여 시각적 현장감을 극대화했습니다.
- **Spatial Audio**: 단순한 BGM이 아닌, 거리감과 방향감이 느껴지는 3D 환경음(빗소리, 군중 소음 등)을 배치하여, 사용자가 귀를 기울이는 방향에 따라 소리가 달라지는 청각적 실재감을 구현했습니다. 이는 사용자의 뇌가 가상 공간을 실제 공간으로 착각(**Place Illusion**)하게 만드는 가장 강력한 기제입니다.

### 2. Body Ownership & Embodiment (신체 소유감 및 체화)

가상 공간에서 '나'라는 존재를 인식하고 몰입하기 위해서는 시각적 일체감이 중요합니다.

- **Visual Consistency (Arm Asset)**: 단순히 공중에 떠 있는 손(Floating Hands) 모델이 아닌, **팔(Arm)까지 연결된 에셋**을 사용하여 시각적 불일치를 해소했습니다. 사용자가 내려다보았을 때 가상의 팔을 자신의 팔로 인식하게 하여(Ownership), 훈련 상황에 대한 주체적 몰입을 유도합니다.

### 3. Locomotion: 자유 이동과 멀미 저감의 균형

텔레포트(Teleport) 방식은 멀미가 적지만, 공간 이동의 연속성을 끊어버려 "위험 지역을 빠져나간다"는 긴박함을 저하할 수 있습니다.

- **Continuous Movement**: 본 프로젝트는 `PlayerManager.cs`를 통해 **Continuous Move(자유 이동)**와 **Continuous Turn(연속 회전)**을 기본 이동 방식으로 채택하였습니다. 사용자는 조이스틱을 이용해 실제 걷는 것처럼 부드럽게 이동하며 사고 현장을 누빕니다.
- **Safety Technology**: 자유 이동 방식의 가장 큰 약점인 사이버 멀미(Cybersickness)를 해결하기 위해 standard XR Component인 **TunnelingVignette**를 적용하였습니다. 이는 플레이어가 이동하거나 회전할 때만 선택적으로 시야를 좁혀(**Dynamic FOV Reduction**), 광류(Optical Flow)로 인한 전정 기관의 혼란을 억제합니다.

### 4. Ray Interaction: 조작 편의성 및 정보 접근성 확보

복잡한 재난 상황에서 UI 조작이나 원거리 선택이 불편하면 훈련의 흐름이 끊기게 됩니다.

- **Code Implementation**: `PlayerManager.cs`에서 제어하는 **XR Ray Interactor**는 손이 닿지 않는 거리의 UI 패널이나 오브젝트를 레이저 포인터처럼 직관적으로 선택하게 합니다.
- **Significance**: 이는 사용자가 훈련 외적인 조작(UI 확인, 메뉴 선택) 스트레스 없이, 빠르고 정확하게 필요한 정보를 습득할 수 있게 하여 인지 부하(Cognitive Load)를 줄여줍니다.

### 5. Direct Interaction: 물리적 체험을 통한 생존 감각 체득

생존 기술 훈련의 핵심은 머리로 아는 것이 아니라 몸으로 기억하는 것입니다.

- **Code Implementation**: `ClimbHandle.cs`와 `XR Direct Interactor`를 통해 구현된 직접 상호작용은 사용자가 기둥이나 벽을 잡을 때 반드시 손을 뻗어 물리적으로 접촉하게 만듭니다. 버튼을 누르는 추상적 행위가 아니라 실제 근육을 사용하는 행위입니다.
- **Significance**: "무언가를 잡고 버틴다"는 물리적 감각은 사용자의 신체 소유감(Body Ownership)을 강화하고, 실제 위기 상황에서도 즉각적인 신체 반응이 나오도록 하는 **체화된 인지(Embodied Cognition)**를 형성합니다.

### 6. NUI: 신체 자세 인식

- **Implementation**: `GestureManager.cs`는 버튼이 아닌 플레이어의 실제 자세(ABC 포즈)를 인식합니다.
- **Significance**: "키를 눌러 방어한다"가 아닌 **"내 몸을 움츠려 방어한다"**는 경험은, 단순한 게임 플레이를 넘어선 실전 훈련으로서의 가치를 증명합니다.

### 7. UI: 공간 단절 없는 인터페이스

VR 환경에서 화면에 고정된(Overlay) UI는 사용자의 초점 심도(Depth Focus) 충돌을 일으키고 현존감을 저해하는 주요 요인입니다.

- **Spatial UI**: **IntroUIManager.cs**는 메뉴와 인터페이스를 3D 공간(World Space) 내에 배치하여 사용자가 UI를 조작하는 동안에도 가상 세계의 몰입이 유지되도록 합니다. 화면에 달라붙는 HUD 방식 대신 공간 속에 위치한 스크린을 사용하는 방식입니다.
- **Diegetic Layout**: 상단(게이지)-중앙(텍스트)-하단(진행바)의 기능적 배치를 통해 사용자의 시야 흐름을 방해하지 않는 최적의 몰입 환경을 제공합니다.

### 8. UX: 다중 감각을 통한 본능적 위기 전달

단순한 시각적 알림만으로는 실제 재난 상황의 긴박함을 전달하기 어렵습니다. 본 프로젝트는 시각, 청각, 촉각이 통합된 **Multi-modal Feedback System**을 구축했습니다.

- **Visual (붉은색 비네팅)**: 압박 수치가 오르면 `PressureVignette.cs`가 작동하여 화면 가장자리를 붉게 물들여 혈압이 오르는 듯한 시각적 압박을 줍니다.
- **Auditory (비명 및 환경음)**: 위험 지역 진입 시 군중의 날카로운 비명 소리와 혼란스러운 환경 사운드를 출력하여 청각적 공포를 조성합니다.
- **Haptic (컨트롤러 진동)**: 사용자가 기둥을 잡거나 자세를 취하는 상호작용을 수행할 때 컨트롤러에 물리적 진동 햅틱을 전달하여 행동의 확실성을 부여합니다.
- **Significance**: 이러한 공감각적 피드백 루프는 사용자의 뇌가 가상 상황을 실제 위협으로 착각하게 만드는 **타당성 착각(Plausibility Illusion)**을 강력하게 유발하여 훈련 효과를 각인시킵니다.
