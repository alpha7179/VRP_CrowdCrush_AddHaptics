# 기술적 구현의 의의 (Technical Significance)

본 프로젝트는 단순한 '체험'을 넘어 '생존 훈련'이라는 교육적 목표를 달성하기 위해, 수업 시간에 다룬 VR 핵심 이론을 코드 레벨에서 정교하게 구현하였습니다. 몰입감을 위한 **자유 이동(Continuous Locomotion)**과 이를 뒷받침하는 **안전 기술(Safety Tech)**, 그리고 편의성과 사실성을 고려하여 분리 설계된 **인터랙션(Interaction)**에 중점을 두었습니다.

### 1. Place Illusion: 고품질 환경 구현을 통한 장소 착각

사용자가 VR 공간을 단순한 그래픽이 아닌 '실제 장소'로 인식하기 위해서는 시각적, 청각적 충실도가 필수적입니다.

- **Realistic Environment**: 본 프로젝트는 실제 도시 환경을 모사한 고품질 3D 에셋(`Tokyo_Street`)을 기반으로, HDRP/URP 파이프라인의 사실적인 라이팅을 적용하여 시각적 현장감을 극대화했습니다.
- **Spatial Audio**: 단순한 BGM이 아닌, 거리감과 방향감이 느껴지는 3D 환경음(빗소리, 군중 소음 등)을 배치하여, 사용자가 귀를 기울이는 방향에 따라 소리가 달라지는 청각적 실재감을 구현했습니다. 이는 사용자의 뇌가 가상 공간을 실제 공간으로 착각(**Place Illusion**)하게 만드는 가장 강력한 기제입니다.

### 2. Body Ownership & Embodiment (신체 소유감 및 체화)

가상 공간에서 '나'라는 존재를 인식하고 몰입하기 위해서는 시각적, 감각적 일체감이 중요합니다.

- **Visual Consistency (Arm Asset)**: 단순히 손이나 컨트롤러 모델이 아닌, **팔까지 연결된 에셋**을 사용하여 시각적 불일치를 해소했습니다. 이는 사용자가 내려다보았을 때 가상의 팔을 자신의 팔로 인식하게 하는(Ownership) 기초가 됩니다.
- **Continuous Locomotion**: 텔레포트가 아닌 **Continuous Move & Turn**을 사용하여, 사용자의 의지대로 공간을 이동하는 감각(Sense of Agency)을 제공합니다.
- **Physical Interaction**: **Direct Interaction**(기둥 잡기)과 **Gesture**(방어 자세)는 버튼 조작이 아닌 신체적 행위를 요구합니다. 이는 "내 몸이 가상 환경에 물리적으로 관여하고 있다"는 강력한 체화(Embodied Cognition) 효과를 줍니다.

### 3. Ray Interaction: 조작 편의성 및 정보 접근성 확보

복잡한 재난 상황에서 UI 조작이나 원거리 선택이 불편하면 훈련의 흐름이 끊기게 됩니다.

- **Code Implementation**: `PlayerManager.cs`에서 제어하는 **XR Ray Interactor**는 손이 닿지 않는 거리의 UI 패널이나 오브젝트를 레이저 포인터처럼 직관적으로 선택하게 합니다.
- **Significance**: 이는 사용자가 훈련 외적인 조작(UI 확인, 메뉴 선택) 스트레스 없이, 빠르고 정확하게 필요한 정보를 습득할 수 있게 하여 인지 부하(Cognitive Load)를 줄여줍니다.

### 4. UI: 공간 단절 없는 인터페이스

VR 환경에서 화면에 고정된(Overlay) UI는 사용자의 초점 심도(Depth Focus) 충돌을 일으키고 현존감을 저해하는 주요 요인입니다.

- **Spatial UI**: `UIFollowHead.cs`는 Lerp 알고리즘을 사용해 UI가 플레이어의 시선을 부드럽게 유영하듯 따라오게 만들었으며, `UIBillboard.cs`는 3D 공간 내에서 항상 정면을 응시하도록 합니다. 이는 HUD 정보가 '게임 UI'가 아닌, **미래형 전술 고글이나 증강 정보(AR)**처럼 느껴지게 합니다.
- **Diegetic Layout**: 상단(게이지)-중앙(텍스트)-하단(진행바)의 기능적 배치를 통해 사용자의 시야 흐름을 방해하지 않는 최적의 몰입 환경을 제공합니다.

### 5. UX: 다중 감각을 통한 본능적 위기 전달

단순한 시각적 알림만으로는 실제 재난 상황의 긴박함을 전달하기 어렵습니다. 본 프로젝트는 시각, 청각, 촉각이 통합된 **Multi-modal Feedback System**을 구축했습니다.

- **Visual (붉은색 비네팅)**: 압박 수치가 오르면 `PressureVignette.cs`가 작동하여 화면 가장자리를 붉게 물들여 혈압이 오르는 듯한 시각적 압박을 줍니다.
- **Auditory (비명 및 환경음)**: 위험 지역 진입 시 군중의 날카로운 비명 소리와 혼란스러운 환경 사운드를 출력하여 청각적 공포를 조성합니다.
- **Haptic (컨트롤러 진동)**: 사용자가 기둥을 잡거나 자세를 취하는 상호작용을 수행할 때 컨트롤러에 물리적 진동 햅틱을 전달하여 행동의 확실성을 부여합니다.
- **Significance**: 이러한 공감각적 피드백 루프는 사용자의 뇌가 가상 상황을 실제 위협으로 착각하게 만드는 **타당성 착각(Plausibility Illusion)**을 강력하게 유발하여 훈련 효과를 각인시킵니다.

### 6. Technical Safety: 멀미 저감 기술

- **TunnelingVignette**: 자유 이동(Continuous Locomotion) 시 발생하는 멀미를 막기 위해 **TunnelingVignette**를 적용했습니다. 이동/회전 시에만 시야각을 동적으로 줄여 전정 기관의 혼란을 기술적으로 방지합니다.
